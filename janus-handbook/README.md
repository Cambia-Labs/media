# The Janus Handbook

## Janus Overview
The Janus platform is modular and scalable microservices environment that is coupled with an engineering methodology for building applications and services rapidly, at scale and with a high level of quality. It is the technical ecosystem that supports integrated applications for Cambia Consumer Solutions and other business entities with a Consumer focus. The Janus platform employs infrastructure as code to programmatically provision infrastructural resources and deploy containerized stacks. These containers are immutable, ensuring that stacks deployed in dev run identically to those in test and prod. The Janus platform embraces the concept of inner source, and we highly encourage developer contributions to and extension of the platform. 

Four high-level objectives we always keep in mind:

* Allow developers to focus on productivity and quality in delivery
* Remove futzing with infrastructure, provisioning and environment
* Make the path of least resistance for developers also the righteous path to security, quality, scalability and maintainability
* Automate, automate, automate!

## Culture Code
The Janus platform team is deliberate about our cultureand builds software that enables developers to fulfill Cambia's mission: 

> To be a catalyst to transform health care, 
creating a person-focused and economically
 sustainable system.


To do that, we have adopted a culture that enables us to hire the best talent, help people unlock their potential, and push toward the vision together.

**Sidebar:** What's culture? It is a set of shared beliefs, values, and practices. Culture happens, planned or not. It behooves us to plan for a culture that we love.

This document is part manifesto, part handbook, and part aspiration. While the content may seem natural and obvious to some of us and foreign to others, it is written down so that we can have open conversations about our culture and get better together as a team.   

### **Beliefs**
We believe what we are working on is VERY important. The Janus platform will enable Cambia to innovate faster at lower cost. We are aiming big. We believe what we are building will also be useful outside of Cambia. We believe we can impact healthcare even more by helping entrepreneurs and other healthcare companies do the same thing thing we are doing at Cambia.

 To achieve this extraordinary goal, we need the culture to match. We aspire to be a high-performing and cohesive team, by how much we:

1. Share information openly, broadly and deliberately.
1. Practice [radical candor](https://www.radicalcandor.com/our-approach/).
1. Deliver with a relentless focus on our Consumers.

By articulating our objectives and goals, being transparent, measuring progress and outcomes, receiving and giving feedback openly, and focusing on delivering value for our customers, we will be in much better position to succeed. Operating this way may put us at odds with the larger company that is in the midst of transformation. We hope to resolve these conflicts the same way we resolve conflicts internal to the Janus team, by being open with information, being open to feedback and criticism, and aiming to deliver value to the customer.

### **Values**  
With the Cambia values serving as the foundation, we are extending/highlighting the following which we think are critically important:
 
#### **We do what we say we'll Do**
If you ask me to join a meeting or take a look at a document and I say yes, I'll do it. When I communicate a release plan or a project plan, I will deliver on it. Commitments should be entered into thoughtfully. If a blocker arises that affects a project or plan, raise your hand and communicate that as soon as possible. Whether you call it reliability, accountability, or trust, we count on each other to execute and that makes work more enjoyable.    

#### **We drive for Impact**  
We help our developers transform their work with the right tools and expertise. We ask how we can do better, we listen to their feedback, and we find ways to innovate and improve their working lives. Our interest in our developer's success comes through in every interaction and stays with us as we build.

#### **We favor autonomy and take ownership**
We like to be transparent with all things our team works on and how we give and receive feedback. However, transparency is about being open. It is not always about making decision by consensus. We each have a voice and we should voice our opinions, we embrace healthy conflict, so we have the most complete set of information, but not always a vote. We want teammates to develop strong decision-making muscles and put them to use. Designated captains for important decisions, when they are reasonably confident of the right bet for us to take, they decide, and we support the bet as a team.

#### **We don't mind failure** 
We will make mistakes, from time-to-time, and they can ultimately help us get to where we want to go. We embrace the fact that mistakes will happen, adopt a learning attitude when they do occur, and enjoy the challenge of pivoting. We do not hide our mistakes, point fingers, and remain stubborn and insist that we are right. 

#### **We show appreciation** 
We bring a positive, can-do attitude. We celebrate victories. We show our support and gratitude with high fives. We assume positive intent. And we are vulnerable with each other and connect as humans.

#### **We are passionate about our Mission and our Metrics**
There are highs and lows and failures and successes when building something new, nebulous, and big. Often this ebbs and flows every day. We choose to do this, and we believe that what we are doing is important and will have a positive impact on healthcare.

We also focus and are obsessed with our metrics. Our metrics tell us how well we are doing; when it doesn't, we figure out how to improve it so that it does. We like to show people our metrics and use it to tell our stories. Our metrics will help us earn the resources to further our mission.

### **Practice**
#### **Learning**
The Janus Platform team is a learning organization.  We invest in people from on-boarding to continuing education and training. As our greatest asset, teammates are encouraged to take on new challenges and grow. We take time to reflect on our work so that we can continue to improve.

#### **Ownership**
Everyone should exercise leadership through "stepping up" and taking ownership. We should all seek to inspire others, cut through sloth, think creatively, hold high standards and strive for greatness.

To support this, we promote open and direct communication to manage conflict. Passive aggressive behavior or gossip is something we discourage.
If you see something going well, feel free to share it so we can do more of it.  If you see something not going well, please elevate it to your manager so we can fix what's broken. Act like an owner and we'll all get stronger.

#### **Quality** 
We pay attention to software quality as a team. We have a culture where quality is owned by all. We are uncovering better ways of ensuring that we write high-quality software. Through this work we have come to value: 

>business requirements driving development **OVER** development before requirements

>thinking about quality at every step **OVER** thinking about quality only at the end

>testing just enough to allow rapid iteration **OVER** testing every possible case

>whole team ownership of quality **OVER** specialist ownership of quality

>enabling quality with tools and processes **OVER** enforcing quality

**Principles**
* Teams must make quality an integrated part of every step of the software development life cycle.

* To assist in this goal, some developers have particular expertise in and focus on quality.

* These quality-focused developers have three primary responsibilities:

1. Provide documentation and training on quality-related tools and processes.
1. Help teams identify gaps in their design, code, tests, or processes that could affect quality, and help them plan how to fill these gaps.
1. Build infrastructure and tools for running tests, reporting quality metrics, documenting features, monitoring quality in production environments, and performing other quality-related tasks

See [Quality Responsibilities](quality-responsibilities.md) for more information on these principles.

#### **Speed** 
We move fast. We deliver change on a daily basis, which will be reported through dynamic, low friction reporting mechanisms. We give and ask for rapid, actionable feedback, so that we can keep up our momentum.

#### **Goal Setting**
To facilitate alignment, we share goals, objectives and results at the appropriate size and cadence. We have a practice of OKRs. This way we can move fast and stay in sync. 

#### **People over Process**
What we do is dynamic and requires people closely working and communicating with each other, and thus we adopt processes judiciously and thoughtfully. We do not mind revamping the way we do things when they don't work. We strive to act and behave like a Day 1 company. We believe process is most often best defined by the people who will use, adopt, and benefit from the process, rather than by a 3rd party, or by a non-representative group.

#### **Efficiency**
We enjoy being focused and shipping great software that solves real problems. In an effort to retain our focus and avoid time-wasting, we try to avoid doing things that do not result in productivity. The following are some suggestions to help facilitate that.

* Meetings that have to happen should have an agenda, an owner, result in action items with accountable individuals, and take no longer than necessary.  Ad-hoc collaborations is still encouraged. 
* Emails
  * Have a punchline, suggestion, or question upfront with description afterward.  
  * Bullet points and brevity are encouraged. 
  * We use the To: and CC: lines to indicate who we are addressing directly (To: line) and who we are keeping informed (CC: line).
  * We use a descriptive email subject line so people can figure out what type of note it is.
* Face-to-face interactions, or a quick call, is probably the best form of communication - if an email thread has gone on for more than three rounds without resolving the issue, talk to the person directly or get the right people face-to-face or on the phone.

#### **Balance**
We all have a life outside of work. At work, we strive to be efficient and effective, and we're going to work hard. But when we go home, or have a conflict during the day, we have the flexibility to turn-off our working brain and focus on the other aspect of our life. This way, we are really at our best when we are here together.

## Engineering Practices
This section represents the nuts and bolts of how we build software. Although companies may use different toolsets for each of these categories, our methodology requires a tool in each category.

*   ### Role of Engineering

    The role of engineering is to fulfill the requirements of the Product organizations that providing funding to CCS Engineering and ultimately to further the [Cambia Cause](https://www.cambiahealth.com/about-us). We do this as efficiently as possible, with the highest security and quality through the practices defined below.
*   ### Team Size & Structure

    Teams can range in size from 5 to 10 members with 7 to 8 as an effective target size that has the scale to deliver while remaining manageable for a dev manager.
*   ### Collaboration 

    Collaboration is a key aspect of our culture and we seek to foster strong collaboration within  engineering teams, among teams and with teams outside of the engineering organization. Only through a tight collaboration with our Product groups can we define and deliver on product vision.
*   ### Conflict Resolution

    We encourage the application of [radical candor](https://www.radicalcandor.com/our-approach/) to provide feedback kindly, clearly, specifically and sincerely. We operate on the principle that everyone is doing their best work and has the best interest of the organization at heart.  When disagreements arise, we address them swiftly and directly. We may disagree, but when a decision has been made, we commit to the decision and move forward. We believe in the judgement of our engineers and encourage the principle of least escalation. If conflicts cannot be resolved among team members, management should be involved. 
*   ### Transparency

    *   We promotes transparency in a number of ways, including:
        *   Documentation spaces in Confluence that are open to anyone to view, as well as project team spaces.
        *   JIRA projects that are open to any authenticated user to view. 
        *   [GitHub repositories](https://github.com/Cambia-Labs/) that are open to any authenticated user to view. 
    *   Work transparency starts with consistently capturing work-in-progress in a source of truth - in our case, Jira.  
    *   Consistently planning and tracking work across engineering teams facilitates transparency by making it easier to understand what's being worked on and when. 
 
*   ### Software Version Control - GitHub

    *   [GitHub - Getting Started](https://github.com)
*   ### CI/CD - CircleCI

    *   [CircleCI - Getting Started](https://circleci.com/)
   
*   ### Single Sign On and Multi-factor Authentication - sAzureAD

    *   [AzureAD - Getting Started](https://azure.microsoft.com/en-us/services/active-directory/)

## How We Make Things

*   ### **Development Principles**

    *   Our software development principles must always be grounded in the following priority order:

        1.  **Security**- protecting the privacy of our customer's health data is always paramount. 

        2.  **Reliability**- features should work correctly. People are trusting us with managing their health, or the health of their loved ones. We need to assist them to the best of our possibilities in getting great care, and certainly not give them false information that would lead to the wrong healthcare decisions. Our focus on quality is part of why we put so much energy into our BDD processes, which are explained below. 

        3.  **Availability**- in order to be someone's trusted partner in their healthcare journey, we need to actually be there all the time/any time. 

        4.  **Maintainability**- our product roadmap is ambitious and the landscape is always getting more complex, so pay it forward to the future you and write maintainable code now so that you can spend more time building new interesting features later. 

        5.  **Telemetry**- if you can't measure it, it doesn't exist. 

        6.  **Performance**- know the performance goals of the system you are building, and know the constraints of all its components. Design for scale. 

        7.  **Feature**- build features that delight our customers. 

*   ### Architectural Patterns

*   ### Architectural Decisions

*   ### Behavior Driven Development

    *   #### Why BDD?

        *   Encourages collaboration between developers, product owners, and other business stakeholders

        *   Increases understanding of the business value impact of each code change

        *   Pushes testing upstream, to catch errors as early as possible

        *   Executable specs = live documentation = building the right things

    *   #### BDD within the Janus Platform

        *   We have standardized on using the open source framework 'Cucumber' for supporting our BDD workflows. There is a strong community of support for integrating things with Cucumber, and the best practices are fairly well documented.
        *   [Read more about how we've implemented Cucumber in Janus here](big-book-of-cucumber.pdf)
*   ### Software Testing

    *   #### **Glossary**

        *   White box = testing internal structures or workings of an application

        *   Black box = testing functionality of an application without peering into its internal structures or workings

        *   Functional = testing of functional requirements

        *   Customer Acceptance = determines if the product or service meets the business goals. Also know as User Acceptance Testing.  

        *   Unit = white box testing of smallest units unit of functionality, typically a method/function

        *   Component = black box testing that limits the scope of the exercised software to a portion of the system under test

        *   Integration = verifies interaction between various software components

        *   API = black box testing, generally concentrating on the business logic layer of the software architecture

        *   Performance = determining the speed or effectiveness of the system

        *   Load = determining how the application behaves under specific loads

        *   Stress = load testing to determine maximums

        *   UI  = graphical user interface testing to ensure it meets its specifications
    *   #### **Strategy** 

        Our test strategy is focused on enabling teams to automatically ensure their stacks are always in a deployable state and ready for integration with other stacks with little manual intervention.

        The ownerships is enabled through the tools and consultation provided by the Quality team. 

        Build time tests are mainly focused on the minimum requirements that the stack builds, runs, and is ready for integration by satisfying the business requirements of clients. If this bar is met, then the stack is ready for integration with other stacks in the DEV environment. Deployment of stack to DEV is validated with tests that fail fast at time of build: 1) exhaustive unit tests and 2) customer acceptance tests to satisfy the business requirements of clients.

        There are additional tests that are performend at pre- and post-deployment to dev. The results of these additional tests are criteria that teams can use to decide how high the bar should be set for deploying a build to higher environments (UAT & PRD). There are several criteria to choose from and these criteria are not one size fits all. 

    *   #### **Standards**

        *   Customer Acceptance Tests are written as Cucumber ‘Gherkin’ scenarios

        *   Cucumber ‘steps’ are implemented using Cucumber Ruby

        *   Performance testing is enabled through a Janus integrated performance testing framework using [Gatling](https://gatling.io/)
    *   #### **Working with Cucumber**

        *   Use business language
        *   Write tests that can be run without any external dependencies. This enables 1) running locally for faster development cycles and 2) parallel development
        *   Always strive to write tests that cleanup after themselves if any state is created 
        *   Cucumber tags used by Janus are:
            * **@SafeForIntegration** is used to execute a scenario during pre-deployment, and again against deployed service in an integration environment
            * **@IntegrationOnly** is used to ONLY execute a scenario against deployed service in an integration environment
            * **@Manual** is used for Scenarios/Features that represent valid business requirements but can't be implemented for automated testing.
            * **@Bug** is used to skip a scenario that exposes a bug.
        *   Scenarios should be reviewed and signed off by the appropriate business stakeholders

        *   **Requirements:**
            *   To build a test container for your service inherit from the Cucumber base image. The cucumber base is responsible for installing standard cucumber gems used for our tests and provides a standard way of executing our acceptance tests. The deployment pipeline in conjunction with cucumber base determines when a service is executed locally vs. in the deployed environment. 
            *   A docker image containing your cucumber tests to execute built from cucumber-base
            *   *   [Common gems](https://git.healthsparq.net/projects/CBI/repos/cucumber-base/browse/cucumber-base-Gemfile) are pre-installed on cucumber-base
            *   A docker-compose file to be used to execute your tests against a locally ran service for pre-deployment verification.
                *   Defines your test service and its dependencies

                *   All test dependencies should be mocked for pre-deployment tests
            *   For more detailed information on how to configure this test image and docker-compose file, refer to the [cucumber-base README](https://git.healthsparq.net/projects/CBI/repos/cucumber-base/browse). 
        *   Run locally using Janus CLI with the `janus cuke` command.

            *   A cucumber.html report will be generated in the root of the project when the test completes.

        *   Automated Reporting
            *   Jenkins Cucumber Plugin renders Pre-Deploy cucumber results for each build
            *   Minerva displayed Pre-Deploy and Post-deploy cucumber results for the currently deployed versio

    *   #### **CI Testing** 

        The Janus Deployment Pipeline validates customer acceptance tests by running all Cucumber scenarios 1) against the stack container pre-deployment, and again 2) against the deployed stack post-deployment. It does this by running a test container which contains all of the Cucumber scenarios specific to the build version of a stack.  

*   *   *   Pre-Deployment Tests
            *   All Cucumber scenarios are run during build, if `run_tests` is enabled in the pipeline-jobs configuration for the stack. 
        *   Post-Deployment Tests
            *   Only Cucumber scenarios tagged @SafeForIntegration will be executed post deployment. 
            *   Post-Deployment tests are executed via [Sunomono](https://git.healthsparq.net/projects/JAN/repos/sunomono/browse) 
            *   Post-Deployment Regression Testing. In addition to a service's own cucumber tests being run post-deployment, the @SafeForIntegration scenarios of all services that depend on said service shall also be run post-deployment. See [Service Dependencies](https://confluence.healthsparq.net/x/pdgpAg#PostDeploymentRegressionTesting)
            *   Performance tests are run using the [Janus integrated performance testing framework](https://cambiahealth.atlassian.net/wiki/display/JANUS/Performance+Testing+with+Shinkansen)

*   *   ### **Debugging**

    *   ### Source Code and Change Management

        <div>Most engineering projects will need to adhere to various compliance and audit practices related to source code and change management.  This engineering guide is trying to steer you and your team towards best practices that work in harmony with compliance requirements.  If your team chooses to deviate from these best practices, you will be assuming the responsibility of either providing justification for why those compliance/audit requirements don't apply or document how your practices support those requirements.</div>

        *   #### Version everything

        *   Everything needed to reproduce any build should be version controlled. That includes:

            *   all build scripts

            *   all key inputs and parameters to build scripts

            *   all necessary binary dependencies, or versioned references to them in a binary repository

        *   To this end, we should focus on writing smart build scripts and maintaining 'dumb' CI servers that simply execute and report on those build scripts
        *   #### Repository Names

        *   Repository names must be all lower case, using dashes to separate words

        *   Stack names should be identical with the repository name. Stack-names should not exceed 63 characters total (limitation of the DNS label. See [https://en.wikipedia.org/wiki/Domain_Name_System](https://en.wikipedia.org/wiki/Domain_Name_System)). Hence, repository names should not exceed 63 characters total.
        *   Self-contained microservices services should be named using a -service suffix

        *   Names should be self-explanatory and should avoid abbreviations. If you need to err, err on the side of overly long, but explicit. rather than abbreviated and cryptic (or possibly overloaded). 

            Names should be consistent–same word means same thing

        *   service names should declare the topic they are responsible for, and not the action they do. For example:

            *   good

                *   reward-identification-service

                *   keyword-management-service

                *   event-google-analytics-service
            *   bad

                *   reward-identifier-service, reward-id-service

                *   keyword-manager-service, keyword-mgr-service, kywrd-mgr-service

                *   event-ga-service
        *   #### Branching Patterns

        *   Projects should try to utilize a 'master' branch / multiple feature branching pattern that supports pull requests as coding tasks is completed and ready for release.  Ideally your master branch is treated as 'releasable' at any given time.  No broken builds, no failing automated tests, deployable, etc.

        *   #### Code Reviews

        *   Teams are encouraged to use Pull Requests into your master branch as a tool to facilitate and document Code Reviews.  A best practice is to have your repository enforce one or more approvers of a Pull Request before merging.  Pull Requests should be made by the primary developer that worked on those changes and approvers can either be other team members, senior team members, etc.  The goal is to ensure that multiple eyes get a chance to review changes to mainline code.  HealthSparq uses Atlassian's Bitbucket product which supports this process natively and integrates into the JIRA framework.  CCS Engineering uses github.com, which also natively supports this process as documented [here](https://docs.github.com/en/github/administering-a-repository/about-required-reviews-for-pull-requests).

    *   ### Documenting Projects

        *   #### Readme

            <div>Every project should have a  **`README`** file - preferably written in Markdown with a  **`.md`** extension.  This allows for easy viewing from our repository viewer.</div>

            <div>The following sections should be provided preferably in this order:</div>

            *   **Overview** - An overview of what this service provides and why someone should use it.  One or two paragraphs at most.
            *   **Data & Compliance** - What data is managed or manipulated by your service - especially data that may be considered Personal Identifying Information or Personal Health Information.  This should again be a summary - easily understood by external stakeholders.  It is NOT expected to be a complete data dictionary.  Though a link to one is useful, if necessary.
            *   **How to Contribute** - Any team specific rules or guidance you might have for contributions.  Pull request processes, branching strategy, etc.
            *   **How to Develop** - Instructions on how to build your project and get it running locally so you can develop and test.
            *   **Contributors** - If your service has identified leads or owners, it's good to put their names in here. This is also a good place to identity any business stakeholders.
            *   [optional] **Third Party Dependencies** - If your service has any external dependencies - they should be listed here.
            *   [optional] **Roadmap** - An overview of future enhancements you have either committed to implement or have possibly deferred.  This gives other teams an idea of where you think this service is going.
            *   [optional] **How to Integrate with this Service** – If input is from some other means than RESTful apis, you should probably include mention of it here and whatever is relevant to the use case: whatever a user (upstream or downstream) of your service might need to know. For instance, if your service consumes or produces messages from/to queues, your README should probably include information on how to produce or consume messages for/from that queue, message contract format, DLQ details, etc. If your service provides only RESTful APIs, but does not include swagger or REST docs (or something similar) to your application, then you may wish to add information here about how another service integrates with this service. Even if you do employ swagger (for instance), you might wish to include, at minimum, a reference to that here. In short, include here whatever might be useful for a user of your service (up or down stream).

A sample file has been committed to the [spring-sample-service](https://git.healthsparq.net/projects/DEV/repos/spring-sample-service/browse) project that currently lives in the dev repository.

*   *   *   *   #### API documentation

                *   See [Janus Engineering Handbook#apidocumentation](https://cambiahealth.atlassian.net/wiki/pages/resumedraft.action?draftId=3995040#JanusEngineeringHandbook-JanusEngineeringHandbook-APIDesignapidocumentation)
            *   #### Maturity tracking

                *   All Janus stacks/services will be measured for maturity and compliance to the standards described in this engineering handbook. [A list of all Janus stacks, and their current state can be found here](https://minerva.dev.janusplatform.io/maturity-matrix.html). 
        *   ### Deploying Code

            *   #### Mission

            *   Application deployments should be:  
                100% automated and driven by code commits, using:  
                100% software defined infrastructure, and  
                100% immutable servers

            *   #### Strategy

            *   Technologies Used

                *   Application packaging
                    *   All microservices are built and containerized using Docker, then pushed to our AWS hosted container registry (ECR)
                    *   All deployments of containers pull from the Elastic Container Registry (ECR) and are 'scheduled' with Elastic Container Service (ECS)
                *   Infrastructure provisioning
                    *   AWS CloudFormation is used for our infrastructure provisioning and configuration management. CloudFormation is idempotent and declarative (like Chef, Puppet & Ansible) with deep integration into all aspects of AWS. 
                    *   CloudFormation syntax itself is just a pile of JSON, so we use a Python framework called [Troposphere](https://github.com/cloudtools/troposphere) which is a higher level language to describe our infrastructure and generate the CloudFormation JSON.
            *   Configuration Layers
                *   We categorize our infrastructure configurations into three layers:

                    *   Janus common
                    *   Environment specific
                    *   Microservice specific
                *   Whenever new code is pushed for a microservice, our build pipeline automatically assembles those three layers to produce CloudFormation Templates (JSON) for that service in each environment. Those templates are stored as build artifacts [in](https://artifactory.healthsparq.com/artifactory/webapp/#/artifacts/browse/tree/General/hsq-services) [Artifactory here](https://artifactory.healthsparq.com/artifactory/webapp/#/artifacts/browse/tree/General/hsq-services).
        *   #### Using The Deployment (Janus) Pipeline

            *   #### **Stack Deployment Environment Promotion**

                *   Stack builds are deployed to environments based on configuration in source control. For more information, see [How to watch, debug, and promote your build](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995181/How+to+watch%2C+debug%2C+and+promote+your+build) 

                *   Teams can leverage [Label Criteria Evaluation](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3996036/Label+Criteria+Evaluation) to perform automated [How To: Label-Based Promotion](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3996121/How+To%3A+Label-Based+Promotion) to higher environments. 

*   *   *   *   **Provisioning resources**
                *   Each microservice will have a deployment configuration file in the root of the repo. The name of the file should be [JanusDeployment.yml & .janus/deploy.yml](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995112)
                    *   **JanusDeployment.yml**
                    *   The JanusDeployment.yml has two top-level sections:
                        *   **resources_I_provision**
                            *   AWS resources (such as S3 buckets or DynamoDB) that 'belong' to each microservice.
                            *   These resources will be created and deployed with each instance of the microservice (and may be removed with a deletion of that service as well)
                        *   **resources_I_consume**
                            *   AWS resources that are provisioned by another microservice, but that this service may need access to. 
                            *   An example might be an SQS queue, which may have many publishers, but only one processor (that removes messages from the queue). 
                            *   **Forward Dependencies**. resources_I_consume should be configured with (among other subelements)    "ecs_services" – the forward dependencies or service(s) it depends on, identified by stack name. Forward dependencies will feed into minerva for display. They are used to derive backward dependencies (services that depend on the service), which in turn can be programmatically consumed for the running of cucumber tests, for instance. Running cucumber (functional) tests of backward dependencies insures that any changes to a forward dependency did not break any of the services that depend on it. For more information about forward and backward dependencies, see [Service Dependencies Design Document](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3994892/Service+Dependencies+Design+Document)
        *   #### How It Works

            *   Comprehensive documentation of how the deployment pipeline works is still a work in progress. For a more detailed view of how everything fits together, refer to [this document](https://cambiahealth.atlassian.net/wiki/spaces/CCSE/pages/744636/CircleCI+Stack-Stage+and+Stack-Deploy+Integrations).

    *   ### How to Get a New Microservice Reviewed and Approved 

        *   See "[How to Get a Stack Reviewed and Approved](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995095)" for detailed information and step-by-step instructions on how to get a new microservice reviewed and approved in terms of Janus compliance and standards.
    *   ### How to Deploy a New Microservice 

*   *   *   See "[How To Deploy a Stack in Janus](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995995)" for detailed information and step-by-step instructions on how to get a new microservice reviewed and approved in terms of Janus compliance and standards.

*   *   ### Enabling Features

        *   TDB
    *   ### Fault Tolerance

        So what are talking about when we talk about fault tolerance? It is a service's built-in ability to continue operating in a well-defined (albeit degraded) fashion when one of its subsystems fails to respond appropriately. Specifically, the running process should act as follows:

        *   **should not** crash if any of the services that it depends on are not available during its life cycle (includes initialization)
        *   **should not** crash when any of its endpoint contracts are violated. E.g.,
            *   if client does not provide all required fields or sends bad data during a service(POST/GET) request.
            *   if a component does not provide all required fields or sends incorrectly-formatted data as part of its GET/POST (or other REST/HTTP verb) response.
        *   **should** report its external health status accurately. It should explicitly state one of its dependencies is down. See [Health Checks](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995550/Health+Checks) for more information.
        *   **should** degrade gracefully. It should complete the requests that it can and report a well defined error for the requests that are not functioning correctly.

        To implement a fault tolerant system, we must take the following famous quote to heart:

        *   "Everything fails all the time” is a famous quote from Werner Vogels, the CTO of Amazon. 

We must expect parts of our system to fail.  We must mitigate for that risk of failure in our architecture so that the overall system won't fail. The following practices are expected of each Janus service:

*   *   *   #### Session State

            *   Services must be stateless and able to operate independently of each other (no sticky sessions)
            *   Accept the fact that you are building a distributed system. Each service will be deployed as part of a load balanced pool so it is critical that they are stateless.
        *   #### Database/Persistent Storage Connectivity

            *   Assume your database is intermittently unavailable. If your service can’t connect to it, fail your health-check and keep retrying. Don’t crash the service or fail to start the service due to lack of database connectivity. Network connections are reset at least once in a 24 hour period. Any long running process is guaranteed to experience failures due to connectivity at least once a day.

*   *   *   #### Self Assessment and Status Reporting

            *   See [Health Checks](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995550/Health+Checks) for details.

*   *   *   #### Circuit Breakers

*   *   *   *   Implement Circuit Breaker Pattern (when appropriate)
            *   **Hystrix**: The Circuit Breaker pattern is one way of detecting failures and preventing the application from continually trying to perform the action until it's safe to retry. The Janus platform will plan to standardize on the [Hystrix library](https://github.com/Netflix/Hystrix) (or alternative but compatible implementations -- see below) for implementing circuit breakers. Hystrix has been ported to most modern languages and standardizing on Hystrix will enable us to leverage centralized reporting tools that can aggregate Hystrix data across all our microservices. 
            *   **Endpoint path:** The endpoint path **must** be named "/hystrix" (no quotes). Various microservice frameworks and service templates (including Spring Boot with its Actuator) include a /hystrix endpoint for easy integration
            *   **Data format:** The format of data returned from a /hystrix endpoint **must** be compatible with the Hystrix metrics event stream data format, as documented at [https://github.com/Netflix/Hystrix/tree/master/hystrix-contrib/hystrix-metrics-event-stream](https://github.com/Netflix/Hystrix/tree/master/hystrix-contrib/hystrix-metrics-event-stream)
            *   **Dashboards, consumers, alerting:** The Janus core team plans to implement centralized tooling for aggregating and alerting off of circuit break events (along with /metrics info). One such example of a simple dashboard is [d](https://medium.com/netflix-techblog/hystrix-dashboard-turbine-stream-aggregator-60985a2e51df)escribed at [https://medium.com/netflix-techblog/hystrix-dashboard-turbine-stream-aggregator-60985a2e51df](https://medium.com/netflix-techblog/hystrix-dashboard-turbine-stream-aggregator-60985a2e51df) and also at [https://github.com/Netflix-Skunkworks/hystrix-dashboard/wiki](https://github.com/Netflix-Skunkworks/hystrix-dashboard/wiki).
            *   **Alternative Implementations:** Development teams **may** use alternative implementations of circuit breakers so long as the roll-up data is exposed in a Hystrix-compatible way at the /hystrix endpoint; conforms to the prescribed data format; and can be consumed by a Hystrix-aware dashboard (and other Hystrix-aware consumers)
            *   For more information on Hystrix metrics and monitoring, see [https://github.com/Netflix/Hystrix/wiki/Metrics-and-Monitoring](https://github.com/Netflix/Hystrix/wiki/Metrics-and-Monitoring)
            *   Some good examples of Hystrix can be learned here: [https://ahus1.github.io/hystrix-examples/manual.html](https://ahus1.github.io/hystrix-examples/manual.html)

*   *   *   **Degrade Gracefully**  
            So what are we talking about when we talk about graceful degradation? Let's say that, a service 'AB' exposes two endpoints, 'A' and 'B' with the following dependency graph:

            *   'A' -> 'X'
            *   'B' -> 'Y'

            'X' and 'Y' are subsystems(data stores), others endpoints, etc... that the 'AB' depends on.

            In the event that 'A' is invoked and 'X' cannot fulfill its obligation, 'A' should report a well defined error to its clients.

            In the event that 'B' is invoked and 'Y' is able complete its obligation, 'B' should complete successfully.

            During a health check, 'AB' should also report that

            *   'A' is not available because 'X' is down
            *   'B' is good to go

 ' Graceful Degradation' is an important component of 'Fault Tolerance'. A system can not be described as 'fault tolerant' if it does not degrade gracefully.

We should be able to automate the testing of basic fault tolerance. Using 'docker compose', we should be able to spin up service with all of its depends. The health-check of the service should report that everything is healthy.

After verifying that the 'all is good' health check is functioning correctly, the next set of tests should

*   *   *   *   *   methodically kill off our service dependents
                *   check return values/error codes
                *   check service health status for correctness

We should continue until all the dependents are down. Then we should reverse the process. Bringing the components back to life should revive our service.

We can use the following a mock/simple servers to facilitate our testing:

*   *   *   *   *   [http://www.mock-server.com/mock_server/getting_started.html](http://www.mock-server.com/mock_server/getting_started.html) for node people
                *   [http://pedestal.io](http://pedestal.io/) for clojure people
                *   [https://github.com/NanoHttpd/nanohttpd](https://github.com/NanoHttpd/nanohttpd) for java

*   *   *   ### API Design

            *   Much (if not all) of the discussion here assumes a RESTful design. 

                *   For the seminal paper on REST, see [https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm](https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm)  

                *   REST and Resource Oriented Architecture. A good reference guide for REST and ROA: <u>[RESTful Web Services](https://learning.oreilly.com/library/view/restful-web-services/9780596529260/)</u>, by Sam Ruby; Leonard Richardson. Published by [O'Reilly Media, Inc.](https://learning.oreilly.com/library/publisher/oreilly-media-inc/), 2007
            *   #### API Design Principles

                *   Characteristics of a Good API

                    *   Easy to learn

                    *   Easy to use, even without documentation

                    *   Hard to misuse

                    *   Easy to read and maintain code that uses it

                    *   Sufficiently powerful to satisfy requirements

                    *   Easy to extend

                    *   Appropriate to audience

                    *   "Write to Your API Early and Often" (see [http://limist.com/coding/talk-notes-how-to-design-a-good-api-and-why-it-matters-josh-bloch.html](http://limist.com/coding/talk-notes-how-to-design-a-good-api-and-why-it-matters-josh-bloch.html) for details on what this means)

                    *   Resource paths should strive to be hierarchical, from larger to smaller. E.g. /v3/maps/northAmerica/usa/california/losangeles

                    *   Favor paths and path variables over query variables (e.g. /v1/chat/summary/user/1234 over /v1/chat/summary?user=1234)

                    *   In many cases, a path variable can be used instead of a query variable. Use "," for ordered items (preserve order) and ";" for unordered items. E.g. /v1/chat/summary/user/1234,4567 – will return two chats, in order, one for user 1234, and then 4567; or /v1/chat/summary/user/1234;4567 if order is not important. 
                    *   Use query variables for algorithmic input (e.g. /v1/chat/summary/user/1234?level=1 to return only one level deep of a user record)
                    *   Resources should be nouns not verbs (e.g.. /v1/chat/summary rather than /v1/chat/summarize)
                *   Maintain Realistic Expectations

                    *   Most API designs are over-constrained

                    *   You won't be able to please everyone

                        *   Aim to displease everyone equally

                        *   Expect to make mistakes

                    *   Real-world use will flush them out

                        *   Expect to evolve API

                *   API Should Be As Small As Possible But No Smaller

                *   API Should Do One Thing and Do it Well

                *   Names Should Be Largely Self-Explanatory

                    *   Avoid cryptic abbreviations

                    *   Be consistent–same word means same thing

                *   Document every class, interface, method, constructor, parameter, and exception

                    *   Class: what an instance represents

                    *   Method: contract between method and its client

                    *   Preconditions, postconditions, side-effects

                    *   Parameter: indicate units, form, ownership

            *   #### Standard API Endpoints

                *   All Janus microservices must implement at least the following standard endpoints:

                *   /docs

                    *   Required.
                    *   Displays documentation, including example requests and responses. The main audience of the /docs is a developer. Imagine you are a new developer and want to quickly become familiar with the application. The /docs endpoint would be one place you could go. 

                    *   Suggested best practice: make /docs a landing page w/ links to swagger api (for request/responses) – if you have an API. If you don't have an API other than the Janus platform requested endpoints (/health, /env, etc.) swagger is not necessary. Also, /docs should include api documentation (e.g. java docs) and/or README information
                *   /env
                    *   Required.
                    *   The list of variables should include at minimum all the runtime variables passed in by the Janus deployment framework such as resource names or tuning parameters. For instance, all the JANUS_* env. variables (JANUS_STACK_NAME, JANUS_ENVIRONMENT, JANUS_STACK_VERSION, JANUS_DNS_SUFFIX, etc.), of which JANUS_STACK_VERSION is used by minerva to compared desired vs. deployed versions. See [JANUS_* environment variables](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3994924/JANUS_*+environment+variables) for a complete list (hopefully current). The Janus deployment framework sets runtime variables in the system environment, exposing system environment variables in the following format would be sufficient:
                    *   <div class="code panel pdl conf-macro output-block" style="border-width: 1px;" data-hasbody="true" data-macro-name="code" data-macro-id="66cd8105-8878-454c-b0af-f426c04caa46">

                        <div class="codeHeader panelHeader pdl" style="border-bottom-width: 1px;">**/env**</div>

                        <div class="codeContent panelContent pdl">

                        <div>

                        <div id="highlighter_576776" class="syntaxhighlighter sh-emacs nogutter  js">

                        <div class="toolbar">[?](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995040/Janus+Engineering+Handbook?flashId=1482004463760df5f2afacf4f7499c59344ce69e#)</div>

                        <table border="0" cellpadding="0" cellspacing="0">

                        <tbody>

                        <tr>

                        <td class="code">

                        <div class="container" title="Hint: double-click to select code">

                        <div class="line number1 index0 alt2">`{`</div>

                        <div class="line number2 index1 alt1">`"systemEnvironment"``: {},`</div>

                        <div class="line number3 index2 alt2">`"systemProperties"``: {}`</div>

                        <div class="line number4 index3 alt1">`}`</div>

                        </div>

                        </td>

                        </tr>

                        </tbody>

                        </table>

                        </div>

                        </div>

                        </div>

                        </div>

                    *   /env could include such data as application runtime environment settings, viz., system properties, JVM properties (if applicable), application configuration settings (from application.properties or application.yml in the case of spring-boot based projects) – whatever a team deems important for consulting when a service that is deployed to and running in a particular environment. (We don't provide SSH access to services and consulting logs of a service to determine environment settings, if they were logged, could be cumbersome.) 
                    *   The /env endpoint should not expose sensitive information such as secrets, credentials, DB connection strings, etc. These things should instead be saved and accessed as secrets using S3 or parameter store (See document on [Secrets](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995875/Secrets%2C+Credentials) for more guidance). It's hard to imagine a case where sensitive data needs to be in an environment variable (and cannot be stored and retrieved in some other fashion), but if there were such a case, you should consider whitelisting your environment variables so that sensitive information is not exposed by the /env endpoint. 

                *   /health

                    *   See [Health Checks](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995550/Health+Checks).

                *   [/hystrix](https://cambiahealth.atlassian.net/wiki/pages/resumedraft.action?draftId=3995040#JanusEngineeringHandbook-hystrix)
                    *   Optional (As of yet, 2019 Feb)
                    *   Show circuit breaker states and statistics (see [Hystrix](https://cambiahealth.atlassian.net/wiki/pages/resumedraft.action?draftId=3995040#JanusEngineeringHandbook-hystrix) section for more info)
                *   /metrics

                    *   Optional (2018 Oct), but in future it will be required and tracked as part of a service's maturity. See [Metrics Endpoint](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995022/Metrics+Endpoint) for details.

                    *   Shows metrics information for the current application.

                    *   Useful runtime metrics at should include:
                        *   successful request counts
                        *   failed request counts
                        *   exceptions thrown
                        *   queue lengths
            *   #### API Versioning

All APIs, internal and external should be versioned using the 'Semantic Version' convention. If you have a personal animus towards symantic versioning, this guy beat you to it, [https://www.youtube.com/watch?v=oyLBGkS5ICk&t=64s](https://www.youtube.com/watch?v=oyLBGkS5ICk&t=64s)

So, what are we talking about when we talk about semantic versioning? The operational definition that we should strive for is given a version number MAJOR.MINOR.PATCH, increment the

*   *   *   *   *   *   MAJOR version when you make incompatible API changes,
                    *   MINOR version when you add functionality in a backwards-compatible manner, and
                    *   PATCH version when you make backwards-compatible bug fixes.

Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.

Following semantic versioning conventions also enable us to deploy services into the wild without affecting any of its dependents. Its dependents should be resilient enough to tolerate any brief outages imposed by service deployment.

For RESTful services, our strategy is even simpler. Use simple version identifiers in the URL path:

*   *   *   *   *   *   https://healthsparq.com/v1/foo

                    *   https://healthsparq.com/v2/foo

                    *   More on the [API versioning discussion here](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995040/Janus+Engineering+Handbook?flashId=1482004463760df5f2afacf4f7499c59344ce69e#).
                *   **API Versioning Deprecation**
                    *   As an application (or service, etc.) evolves over time, it will have at least 2 (possibly more) versions of an API.
                    *   An application should not have more than 3 versions of an API at any one time. Ideally only 2.
                    *   An older version of an API should be deprecated within one month from the time that a newer version of the API is added
                    *   It is the responsibility of service owner of the API to publish/communicate with consumers of the API that an API version has been deprecated. Suggested means of publishing/communicating the deprecation of an API include adding a notice in the stack's README, adding a notice in the stack's swagger docs, emailing the service owners and/or teams of consumers of the API.
                    *   Consumers of an older API version have 3 months from the time of deprecation AND/OR the time that they are made aware of the deprecation, to use the new version and stop using the older version.
                    *   After 3 months from deprecation and communication of the deprecation, a service owner may remove an older version. 
            *   #### API Communication (Links)

                *   All new APIs must standardize on Hypertext Application Language (HAL).
                    *   HAL is a "generic media type with which Web APIs can be developed and  exposed as series of links. Clients of these APIs can select links by their link relation type and traverse them in order to progress through the application....The primary design goals of HAL are generality and simplicity. HAL can be applied to many different domains, and imposes the minimal amount of structure necessary to cover the key requirements of a hypermedia Web API."
                    *   HAL provides a standard way for expressing the resources and relationships of an API as hyperlinks. Using HAL, you use HTTP methods (GET, PUT, POST, DELETE) to submit requests and receive information about the API in the response. Applications can use the information returned to explore the functionality of the API.
                    *   HAL based APIs must return a Content-Type of "application/hal+json" to be compliant.
                    *   Ideally, we should have helper libraries for each language. This will allow for a Janus-compliant standard of such things as "errors", "pagination", etc. in addition to "_links" or "_embedded".
                    *   All new RESTful services, with HAL-based APIs, _must_ return links in their positive responses (100, 200, 300).
                    *   HAL-based APIs _may_ return links in their error responses (400, 500) where and when they have control over the response (vs. the underlying application server). 
                *   [A great learning document for HAL is here](http://stateless.co/hal_specification.html).
                    *   [The full IETF (draft) spec for HAL is here](http://tools.ietf.org/html/draft-kelly-json-hal-06).
                *   More information on links and HATEOS from Roy Fielding (the "father" or REST): 
                    *   Blog on HATEOS: [https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven](https://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven) 
                    *   REST Architectural style: [https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm](https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm)  

            *   #### RESTful Endpoints

                RESTful services should follow the HTTP specification (HTTP specification being the de facto implementation of REST) as closely as possible to ensure a uniform contract across endpoints in a single service and all endpoints in all services on the Janus platform. This includes choosing the right http verb (GET, POST, PUT, etc.) for the right action, returning the most appropriate http status code for the response based on the result of the action, etc. according to the HTTP specification as outline here: [https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html#sec9.5](https://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html#sec9.5). For instance a successful POST request should return a 201 http status code with a Location response header pointing to the new URI: "If a resource has been created on the origin server, the response SHOULD be 201 (Created) and contain an entity which describes the status of the request and refers to the new resource, and a Location header... "

                *   **HTTP Verb**. The right verb should be chosen for the right RESTful operation, whenever possible. For instance, use GET to request a resource, use POST to create a new resource, use PUT to idempotently modify an existing resource, etc. There are cases where POST might be preferred to PUT or GET, but if you code an exception, you should be prepared to explain the reasoning behind it. 
                *   **HTTP Response Codes.** RESTful APIs should return the http response code most appropriate to the action and response, as outlined here: [https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html](https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html). For instance, successful responses should be in the 2xx range; a successful POST request that resulted in an resource creation, should return an http status code of 201\. A successful PUT request whereby the target resource was modified should return an HTTP status code of 200: "If an existing resource is modified, either the 200 (OK) or 204 (No Content) response codes SHOULD be sent to indicate successful completion of the request." 

        *   ### Scaling Patterns

            *   #### Overview

                *   Horizontal scaling, also known as scaling out, is a term to describe the increase of system computing capacity by adding compute nodes to a distributed software application. Vertical scaling, also known as scaling up, is a term to describe the increase of capacity by adding resources (such as additional CPUs or memory) to a single compute node.  
                    Our goal is to automate horizontal scaling at the individual microservice service level. To support that goal, each instance of a microservice should be completely stateless, or if necessary store any shared data or session state in an external persistent data store (like a Dynamo table or S3 bucket).

            *   #### Auto-scaling Mechanics

                *   Our strategy is to leverage AWS Auto-Scale Groups (ASGs) for each of our microservices.

                    *   Each ASG will be fronted by an Amazon Elastic Load Balancer (ELB) to manage session routing and distribution

                *   All microservices will be deployed with a minimum of 2 nodes per ASG

                    *   Define relevant auto-scaling metrics for each microservice.

                *   Scaling rules can be configured uniquely for each ASG. We will attempt to configure scaling rules that make sense for each microservice they are supporting. For example, some microservices can be scaled based on CPU load, while it might make more sense to scale others based on a job queue length, etc..

                    *   The bulk of the ASG provisioning mechanics will be handled by the same container deployment pipeline described in <the Deploying Code section>.

        ### Sidecar Container Configuration

        <div> 

        *   Sidecar configuration for the Janus Platform is discussed [here](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995637/Sidecar+Container+Configuration+on+the+Janus+Platform).

        </div>

        ### Programming Languages and Frameworks

        *   #### Overview

            *   Microservices can be written using different frameworks or programming languages, and you can deploy them independently as a single service or a group of services. So the most important aspects of interoperability in a microservice environment are the interface contracts between those services. However, while the ‘internal’ implementation of each service is inherently more flexible, we still want to make some effort to standardize on implementation technologies for the sake of sharing more resources across the organization. This section describes some of the current technology standards in the Janus Platform. For updating or changing any of these standards, please read the section on ‘Evolving Standards’.

*   *   *   *   #### Helper Libraries by Language

                *   [Janus Helper Libraries in General](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3997674/Helper+Libraries) 
                *   [Janus Helper Libraries: Features by Language](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3996125/Janus+Helper+Libraries%3A+Features+by+Language)
            *   #### Current Standards

            *   Front-end/UI
            *   <placeholder>
            *   Back-end/microservices 
            *   Java

*   *   *   *   *   at least version 8 
                *   SpringBoot framework. 
                *   build target= embedded Jetty, standalone
                *   Bulk heading: Netflix Hystrix for circuit breaker patterns
                *   Health checks: implement Spring Boot’s HealthIndicator interface, or register a customer indicator
                *   Metrics: [Spring Boot’s metrics functionality](http://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-metrics.html) works well at of the box. To record your own metrics inject a CounterService and/or GaugeService into your bean.
                *   A sample SpringBoot service template is [in BitBucket here](https://git.healthsparq.net/projects/DEV/repos/spring-sample-service)
                *   Clojure
                    *   A sample project and documentation is being built now...stay tune
            *   Packaging/Containerization
                *   Overview:

*   *   *   *   *   *   The standard unit of deployment is a container, and the standard interface from development to deployment is the container registry. All microservices will be containerized with Docker and pushed to our container registry for deployments. The deployment infrastructure will pull all containers from the registry.Working with Docker
                    *   <placeholder for local installation instructions environment configuration recommendations>
            *   Data Persistence
                *   As a general rule, reach for DynamoDB as your first choice for data persistence. If a relational data store is a better fit for your data, then go for PostgreSQL.
                *   DynamoDB

*   *   *   *   *   *   Features: Highly scaleable and performant NoSQL datastore. Fully managed by AWS and HIPAA compliant. Takes advantage of integrated AWS security groups for easiest per-stack permissions management without need for users and passwords.  working with DynamoDB
                    *   Don’t use the Java DynamoDBMapper Class. It provides standard Java ORM style mapping to DynamoDB instead of encouraging native NoSQL thinking and data modeling.
                *   PostgreSQL
                    *   <placeholder>
            *   #### Developing in AWS

                *   [Local Development Environment](https://cambiahealth.atlassian.net/wiki/spaces/CCSE/pages/744542/CircleCI+-+Migrate+From+Jenkins+to+Circleci#Local-Development---Environment)

                    *   install the AWS CLI

                *   *   *   [Official instructions from AWS](http://docs.aws.amazon.com/cli/latest/userguide/installing.html)

                        *   or on a Mac, if you use [homebrew](http://brew.sh/), you can imply run ‘brew install awscli' 

                        *   run ‘aws configure’ and supply the AWS IAM credentials you received from the Ops team

                            *   set the default region to be ???

                        *   Developing local for integration with AWS services

                            *   *   add the line ‘region=local’ to your .aws/config file

                    *   SQS

                        *   [https://github.com/iain/fake_sqs](https://github.com/iain/fake_sqs)

                    *   DynamoDB

                        *   Use dynamodb-local for local development and testing 

                        *   The easiest way to run dynamodb-local is with the `docker-registry.janusplatform.io/janus/dynamodb-local:latest` Docker image, which defaults to an in-memory database, listens on port 8000, and does not require any credentials. You can start it by running this command:

_docker run -p 8000:8000 docker-registry.janusplatform.io/janus/dynamodb-local:latest_

*   *   *   *   *   *   *   See the [official AWS documentation for DynamoDB-Local here](https://aws.amazon.com/blogs/aws/dynamodb-local-for-desktop-development/)
                        *   [Basic DynamoDB Tutorial](http://docs.aws.amazon.com/amazondynamodb/latest/gettingstartedguide/GettingStarted.JsShell.html)
                        *   [Integration Testing with DynamoDB-Local](https://thecarlhall.wordpress.com/2015/11/14/integration-testing-with-dynamodb-locally/)

*   *   *   *   *   Pointing at DynamoDB local

                    *   When running AWS commands from the CLI, you can add "--endpoint-url [http://localhost:8000](http://localhost:8000/)”

            *   #### Coding Standards

                *   <placeholder>

            *   #### Service Discovery

                *   AWS has an excellent reference architecture for a service discovery solution that does not require any client side libraries or extra server infrastructure. The solution makes use of dynamically managed internal DNS zones that are updated by load balancer events as new services are deployed. [The details of a solution, including all of the necessary source code can be found here](https://github.com/awslabs/ecs-refarch-service-discovery/).

        *   Each application environment will have its own DNS subdomain. Only one version of a microservice will be available at a time per environment. 

            *   The legacy environments map to the new microservice environments as follows:

                <div class="table-wrap">

                <table class="wrapped confluenceTable" resolved=""><colgroup><col><col></colgroup>

                <tbody>

                <tr>

                <td class="confluenceTd">

                **Legacy Environment**

                </td>

                <td class="confluenceTd">

                **Microservice Environment**

                </td>

                </tr>

                <tr>

                <td class="confluenceTd">

                DEV & internal sandboxes

                </td>

                <td class="confluenceTd">

                DEV2

                </td>

                </tr>

                <tr>

                <td class="confluenceTd">

                CIDEV

                </td>

                <td class="confluenceTd">

                CIDEV2

                </td>

                </tr>

                <tr>

                <td class="confluenceTd">

                INTEGRATION

                </td>

                <td class="confluenceTd">

                INT2

                </td>

                </tr>

                <tr>

                <td class="confluenceTd">

                QADEPLOY

                </td>

                <td class="confluenceTd">

                QADEPLOY2

                </td>

                </tr>

                <tr>

                <td class="confluenceTd">

                all client sandboxes & DEV3

                </td>

                <td class="confluenceTd">

                UAT2

                </td>

                </tr>

                <tr>

                <td class="confluenceTd">

                STG

                </td>

                <td class="confluenceTd">

                PERF2

                </td>

                </tr>

                <tr>

                <td colspan="1" class="confluenceTd">PRDQA</td>

                <td colspan="1" class="confluenceTd">PRDQA2</td>

                </tr>

                <tr>

                <td class="confluenceTd">

                PRD

                </td>

                <td class="confluenceTd">

                PRD2

                </td>

                </tr>

                </tbody>

                </table>

                </div>

            *   Services should call each other through fully qualified domain aliases. For example, if you are in the DEV2 environment and need to call the geocoding service, you would call geocoding.dev2.healthsparq.com

            *   A service will 'know' it's current environment from the value of the HSQENVIRONMENT variable. 
            *   For new microservices HSQENVIRONMENT is passed in as an environment variable
            *   For legacy applications the HSQENVIRONMENT value is set in the XPRODUCT/ENV_URL table (under the key HSQENVIRONMENT)
            *   Putting all of that together, your service would insert the value of HSQENVIRONMENT into the FQDN. For example:

            *   HSQ1 connecting to the geocoding-service would connect to the geocoding-service.$[HSQENVIRONMENT.healthsparq.com](http://hsqenvironment.healthsparq.com/)

        *   #### Evolving Standards

            *   <placeholder>
            *   ### Build vs Buy

### Security Compliance

Security is a shared responsibility on Janus. The platform itself provides some of the foundational security compliance, so that the service engineers could focus on security compliance unique to their service architecture and code. More detailed information on [Janus security compliance is available here.](https://cambiahealth.atlassian.net/wiki/display/JANUS/Janus+Security+Compliance) 

#### Application Security - Across Cambia

Recommended checklist to use during planning, design and development phases - [SSDLC Product Checklist Template](https://cambiahealth.atlassian.net/wiki/display/INFOSEC/SSDLC+Product+Checklist+Template)

Recommended set of web security and application security guidelines that everyone in the organization are mandated to follow - [Web Security Requirements Checklist](https://cambiahealth.atlassian.net/wiki/display/INFOSEC/Web+Security+Requirements+Checklist)

#### Application Security - Platform specific 

In addition to the rules above, security compliance expectations for services hosted on the Janus platform can be found in detail here- [Janus Application Security & Compliance Requirements](https://cambiahealth.atlassian.net/wiki/pages/viewpage.action?pageId=3995968)

To allow services to securely communicate with each other, Janus services use a model of service white-listing. More details on that here - [Service Dependencies Design Document](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3994892/Service+Dependencies+Design+Document)

#### Data Security 

The [data classification levels](https://cambiahealth.sharepoint.com/sites/InformationSecurity/Shared%20Documents/Forms/AllItems.aspx?id=%2Fsites%2FInformationSecurity%2FShared%20Documents%2FSupplier%20Security%20Risk%20Management%2FVendor%20Assessment%20Documentation%2FCambia%20Data%20Classification%20Pyramid%2Epdf&parent=%2Fsites%2FInformationSecurity%2FShared%20Documents%2FSupplier%20Security%20Risk%20Management%2FVendor%20Assessment%20Documentation&RootFolder=%2Fsites%2FInformationSecurity%2FShared%20Documents%2FSupplier%20Security%20Risk%20Management%2FVendor%20Assessment%20Documentation&FolderCTID=0x0120005660AA8B4A7D1548B707E6261646F83C) in Janus are based on sensitivity and security. Janus services are expected to be completely aware of their data classification levels prior to their deployment. 

For a thorough review of how data is classified, refer to [Data Sensitivity Classification](https://cambiahealth.atlassian.net/wiki/spaces/JANUS/pages/3995277/Data+Sensitivity+Classification).

## How We Operate Things

*   *   ### Monitoring & Alerting

        *   TODO: complete this section. 
    *   ### Logging

        *   TODO: replace with overview of Datadog in Janus, remove references to Kibana

Janus supports several types of logging. It’s important to correctly classify your use case into one of these categories to properly meet the platform expectations and data handling requirements. It may be helpful to think about the “purpose” that is intended for the events being logged. A single event may be logged in more than one way if it is needed for several purposes.

*   *   *   #### Application Events

            *   Purpose: Monitoring and debugging services

            *   PHI: NOT ALLOWED 

            *   Structured. Application logs must be be structured. You may use a helper library for this. For more information, see [helper libraries structured logging](https://confluence.healthsparq.net/x/DYNWAg).

            *   Method: Any output written to the console (stdout) will be automatically captured via CloudWatch and routed to Kibana for easy filtering and searching. Separate instances of Elasticsearch & Kibana exist for each Janus environment, as follows:

            *   CCS-Janus - DEPRECATED

                *   dev: [http://kibana.dev.janusplatform.io/](http://kibana.dev.janusplatform.io/) 

                *   uat: [http://kibana.uat.janusplatform.io/](http://kibana.uat.janusplatform.io/)
                *   prd: [http://kibana.prd.janusplatform.io/](http://kibana.prd.janusplatform.io/)

                Healthsparq-Janus - DEPRECATED

                *   Dev2: [http://kibana.dev2.janusplatform.io/](http://kibana.dev2.janusplatform.io/) 

                *   CIDev2: [http://kibana.cidev2.janusplatform.io](http://kibana.cidev2.janusplatform.io/)

                *   Int2: [http://kibana.int2.janusplatform.io](http://kibana.int2.janusplatform.io/)

                *   UAT2: [http://kibana.uat2.janusplatform.io](http://kibana.uat2.janusplatform.io/)

                *   QADeploy2: [http://kibana.qadeploy2.janusplatform.io](http://kibana.qadeploy2.janusplatform.io/)

                *   Perf2: [http://kibana.perf2.janusplatform.io](http://kibana.perf2.janusplatform.io/)

                *   PrdQA2: [http://kibana.prdqa2.janusplatform.io](http://kibana.prdqa2.janusplatform.io/)

                *   Prd2: [http://kibana.prd2.janusplatform.io  

                    ](http://kibana.prd2.janusplatform.io/)

        *   #### Audit Events** [[1]](https://cambiahealth.atlassian.net/wiki/pages/resumedraft.action?draftId=3995040#JanusEngineeringHandbook-LoggingAuditEvents)**

            *   Purpose: Tracking historical state of data

            *   PHI: Allowed, but must be stored in a compliant manner (encrypted at rest, encrypted in transit)

            *   Method: The service that created the event is responsible for "owning" its own audit data and thus determining how it is logged. For example, the COUPP service is responsible for the historical state of the COUPP text. And the Preference service is responsible for tracking historical state of preference selections. [[1]](https://cambiahealth.atlassian.net/wiki/pages/resumedraft.action?draftId=3995040#JanusEngineeringHandbook-LoggingAuditEvents)

        *   #### Business/Analytics Events

            *   Purpose: Tracking historical user and service events that are interesting to the business for possible future reporting and/or analytics.

            *   PHI: Allowed; see service documentation for appropriate usage.

            *   Method: Logged via an API call to the event-logging-service

            *   API Docs: [https://event-logging-service.dev2.healthsparq.com/docs/](https://event-logging-service.dev2.healthsparq.com/docs/)

            *   Service README: [https://github.com/cambiahealth/event-logging-service](https://github.com/cambiahealth/event-logging-service)

            *   Where to see: TBD

*   *   ### Container Management

    *   ### Service Discovery

    *   ### Access to Production

    *   ### Data Integrity

    *   ### Service Configurations

    *   ### Incident Response

    *   ### Disaster Recovery